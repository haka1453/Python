{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated features\n",
    "\n",
    "Often datasets contain duplicated features, that is, features that despite having different names, are identical.\n",
    "\n",
    "In addition, we may often introduce duplicated features when performing **one hot encoding** of categorical variables, particularly if our datasets have many and /or highly cardinal categorical variables.\n",
    "\n",
    "Identifying and removing duplicated, and therefore redundant features, is an easy first step towards feature selection and more interpretable machine learning models.\n",
    "\n",
    "Here I will demonstrate how to identify duplicated features using a dataset that I created for this course. \n",
    "\n",
    "There is no function in Pandas to find duplicated columns. So we need to write a bit code to do so.\n",
    "\n",
    "**Note**\n",
    "Finding duplicated features can be a computationally costly operation in Python, therefore depending on the size of your dataset, you might not always be able to do it.\n",
    "\n",
    "This method that I describe here to find duplicated features works for both **numerical and categorical** variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 301)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('../dataset_1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the presence of missing data.\n",
    "# (there are no missing data in this dataset)\n",
    "\n",
    "[col for col in data.columns if data[col].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1), # drop the target\n",
    "    data['target'], # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove constant and quasi-constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove constant and quasi-constant features first:\n",
    "# we can remove the 2 types of features together with this code\n",
    "# (we used it in our previous notebook)\n",
    "\n",
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate predominant feature: do more than 99% of the observations\n",
    "    # show 1 value?\n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 158), (15000, 158))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then drop these columns from the train and test sets:\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated features\n",
    "\n",
    "To identify duplicated variables we need to iterate through all features of our dataset, and for each and every feature, try and find others that are identical, or duplicates.\n",
    "\n",
    "We will create a dictionary of {variable: duplicated variables} pairs to identify them more easily throughout the demo. Keep in mind that in a dataset, there could be 2 or more features that are identical to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# check for duplicated features in the training set:\n",
    "\n",
    "# create an empty dictionary, where we will store \n",
    "# the groups of duplicates\n",
    "duplicated_feat_pairs = {}\n",
    "\n",
    "# create an empty list to collect features\n",
    "# that were found to be duplicated\n",
    "_duplicated_feat = []\n",
    "\n",
    "\n",
    "# iterate over every feature in our dataset:\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    \n",
    "    # this bit helps me understand where the loop is at:\n",
    "    if i % 10 == 0:  \n",
    "        print(i)\n",
    "    \n",
    "    # choose 1 feature:\n",
    "    feat_1 = X_train.columns[i]\n",
    "    \n",
    "    # check if this feature has already been identified\n",
    "    # as a duplicate of another one. If it was, it should be stored in\n",
    "    # our _duplicated_feat list.\n",
    "    \n",
    "    # If this feature was already identified as a duplicate, we skip it, if\n",
    "    # it has not yet been identified as a duplicate, then we proceed:\n",
    "    if feat_1 not in _duplicated_feat:\n",
    "    \n",
    "        # create an empty list as an entry for this feature in the dictionary:\n",
    "        duplicated_feat_pairs[feat_1] = []\n",
    "\n",
    "        # now, iterate over the remaining features of the dataset:\n",
    "        for feat_2 in X_train.columns[i + 1:]:\n",
    "\n",
    "            # check if this second feature is identical to the first one\n",
    "            if X_train[feat_1].equals(X_train[feat_2]):\n",
    "\n",
    "                # if it is identical, append it to the list in the dictionary\n",
    "                duplicated_feat_pairs[feat_1].append(feat_2)\n",
    "                \n",
    "                # and append it to our monitor list for duplicated variables\n",
    "                _duplicated_feat.append(feat_2)\n",
    "                \n",
    "                # done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore our list of duplicated features\n",
    "len(_duplicated_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 6 features that were duplicates of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_148', 'var_199', 'var_296', 'var_250', 'var_232', 'var_269']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the ones:\n",
    "\n",
    "_duplicated_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_4': [],\n",
       " 'var_5': [],\n",
       " 'var_8': [],\n",
       " 'var_13': [],\n",
       " 'var_15': [],\n",
       " 'var_17': [],\n",
       " 'var_18': [],\n",
       " 'var_19': [],\n",
       " 'var_21': [],\n",
       " 'var_22': [],\n",
       " 'var_25': [],\n",
       " 'var_26': [],\n",
       " 'var_27': [],\n",
       " 'var_29': [],\n",
       " 'var_30': [],\n",
       " 'var_31': [],\n",
       " 'var_35': [],\n",
       " 'var_37': ['var_148'],\n",
       " 'var_38': [],\n",
       " 'var_41': [],\n",
       " 'var_46': [],\n",
       " 'var_47': [],\n",
       " 'var_49': [],\n",
       " 'var_50': [],\n",
       " 'var_51': [],\n",
       " 'var_52': [],\n",
       " 'var_54': [],\n",
       " 'var_55': [],\n",
       " 'var_57': [],\n",
       " 'var_58': [],\n",
       " 'var_62': [],\n",
       " 'var_63': [],\n",
       " 'var_64': [],\n",
       " 'var_68': [],\n",
       " 'var_70': [],\n",
       " 'var_74': [],\n",
       " 'var_75': [],\n",
       " 'var_76': [],\n",
       " 'var_79': [],\n",
       " 'var_82': [],\n",
       " 'var_83': [],\n",
       " 'var_84': ['var_199'],\n",
       " 'var_85': [],\n",
       " 'var_86': [],\n",
       " 'var_88': [],\n",
       " 'var_91': [],\n",
       " 'var_93': [],\n",
       " 'var_94': [],\n",
       " 'var_96': [],\n",
       " 'var_100': [],\n",
       " 'var_101': [],\n",
       " 'var_103': [],\n",
       " 'var_105': [],\n",
       " 'var_107': [],\n",
       " 'var_108': [],\n",
       " 'var_109': [],\n",
       " 'var_110': [],\n",
       " 'var_114': [],\n",
       " 'var_117': [],\n",
       " 'var_118': [],\n",
       " 'var_119': [],\n",
       " 'var_121': [],\n",
       " 'var_123': [],\n",
       " 'var_128': [],\n",
       " 'var_131': [],\n",
       " 'var_132': [],\n",
       " 'var_134': [],\n",
       " 'var_137': [],\n",
       " 'var_139': [],\n",
       " 'var_140': [],\n",
       " 'var_143': ['var_296'],\n",
       " 'var_144': [],\n",
       " 'var_145': [],\n",
       " 'var_147': [],\n",
       " 'var_152': [],\n",
       " 'var_154': [],\n",
       " 'var_155': [],\n",
       " 'var_156': [],\n",
       " 'var_157': [],\n",
       " 'var_160': [],\n",
       " 'var_161': [],\n",
       " 'var_162': [],\n",
       " 'var_163': [],\n",
       " 'var_164': [],\n",
       " 'var_165': [],\n",
       " 'var_166': [],\n",
       " 'var_168': [],\n",
       " 'var_169': [],\n",
       " 'var_172': [],\n",
       " 'var_173': [],\n",
       " 'var_174': [],\n",
       " 'var_175': [],\n",
       " 'var_176': [],\n",
       " 'var_177': ['var_250'],\n",
       " 'var_179': [],\n",
       " 'var_181': [],\n",
       " 'var_185': [],\n",
       " 'var_186': [],\n",
       " 'var_188': [],\n",
       " 'var_190': [],\n",
       " 'var_191': [],\n",
       " 'var_192': [],\n",
       " 'var_193': [],\n",
       " 'var_194': [],\n",
       " 'var_198': [],\n",
       " 'var_200': [],\n",
       " 'var_203': [],\n",
       " 'var_205': [],\n",
       " 'var_206': [],\n",
       " 'var_207': [],\n",
       " 'var_208': [],\n",
       " 'var_209': [],\n",
       " 'var_213': [],\n",
       " 'var_214': [],\n",
       " 'var_218': [],\n",
       " 'var_220': [],\n",
       " 'var_222': [],\n",
       " 'var_226': ['var_232'],\n",
       " 'var_229': ['var_269'],\n",
       " 'var_230': [],\n",
       " 'var_231': [],\n",
       " 'var_238': [],\n",
       " 'var_240': [],\n",
       " 'var_241': [],\n",
       " 'var_242': [],\n",
       " 'var_244': [],\n",
       " 'var_252': [],\n",
       " 'var_253': [],\n",
       " 'var_255': [],\n",
       " 'var_256': [],\n",
       " 'var_258': [],\n",
       " 'var_259': [],\n",
       " 'var_261': [],\n",
       " 'var_262': [],\n",
       " 'var_266': [],\n",
       " 'var_268': [],\n",
       " 'var_270': [],\n",
       " 'var_271': [],\n",
       " 'var_272': [],\n",
       " 'var_273': [],\n",
       " 'var_275': [],\n",
       " 'var_276': [],\n",
       " 'var_277': [],\n",
       " 'var_278': [],\n",
       " 'var_279': [],\n",
       " 'var_281': [],\n",
       " 'var_284': [],\n",
       " 'var_288': [],\n",
       " 'var_292': [],\n",
       " 'var_293': [],\n",
       " 'var_295': [],\n",
       " 'var_300': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore the dictionary we created:\n",
    "\n",
    "duplicated_feat_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for every feature, if it had duplicates, we have entries in the list, otherwise, we have empty lists. Let's explore those features with duplicates now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "# let's explore the number of keys in our dictionary\n",
    "\n",
    "# we see it is 152, because 6 of the 158 were duplicates,\n",
    "# so they were not included as keys\n",
    "\n",
    "print(len(duplicated_feat_pairs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_37 ['var_148']\n",
      "\n",
      "var_84 ['var_199']\n",
      "\n",
      "var_143 ['var_296']\n",
      "\n",
      "var_177 ['var_250']\n",
      "\n",
      "var_226 ['var_232']\n",
      "\n",
      "var_229 ['var_269']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the features with its duplicates\n",
    "\n",
    "# iterate over every feature in our dict:\n",
    "for feat in duplicated_feat_pairs.keys():\n",
    "    \n",
    "    # if it has duplicates, the list should not be empty:\n",
    "    if len(duplicated_feat_pairs[feat]) > 0:\n",
    "\n",
    "        # print the feature and its duplicates:\n",
    "        print(feat, duplicated_feat_pairs[feat])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17967</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_37  var_148\n",
       "17967       0        0\n",
       "32391       0        0\n",
       "9341        0        0\n",
       "7929        0        0\n",
       "46544       0        0\n",
       "4149        0        0\n",
       "33426       0        0\n",
       "3002        0        0\n",
       "6974        0        0\n",
       "16864       0        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check that indeed those features are duplicated\n",
    "# I select a pair from above\n",
    "\n",
    "X_train[['var_37', 'var_148']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  6,  9, 12, 21, 33, 15], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_37'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  6,  9, 12, 21, 33, 15], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_148'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37493</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20251</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48480</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31607</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41172</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46118</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_37  var_148\n",
       "37493       3        3\n",
       "20251       6        6\n",
       "4264        6        6\n",
       "48480       3        3\n",
       "31607       3        3\n",
       "41172       3        3\n",
       "13502       3        3\n",
       "7759        3        3\n",
       "46118       3        3\n",
       "2638        3        3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore parts of the dataframe where the values in\n",
    "# these features are different from 0:\n",
    "\n",
    "X_train[X_train['var_37'] != 0][['var_37', 'var_148']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, these features are indeed identical :)\n",
    "\n",
    "There are more duplicated features in this dataset, which we removed because they are constant or quasi-constant. So as an exercise, why don't you try and find which additional features in this dataset are duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 152), (15000, 152))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, to remove the duplicates, what we are going to do is to retain\n",
    "# the keys of the dictionary\n",
    "\n",
    "# do you understand why? if not, go back to our loop in cell 7 and try to \n",
    "# determine the reason\n",
    "\n",
    "X_train = X_train[duplicated_feat_pairs.keys()]\n",
    "X_test = X_test[duplicated_feat_pairs.keys()]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how we further reduced our dataset by 6 additional features. \n",
    "\n",
    "In summary, by removing constant, quasi-constant and duplicated features, we reduced our original **300** feature dataset to a **152** feature dataset. Well done us!\n",
    "\n",
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

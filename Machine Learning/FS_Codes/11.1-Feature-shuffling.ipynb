{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection by Random Shuffling\n",
    "\n",
    "A popular method of **feature selection** consists in **random shuffling the values of a specific variable** and determining **how that permutation affects the performance metric of the machine learning algorithm**. In other words, the idea is to **permute the values of each feature**, one feature at the time, and **measure how much the permutation (or shuffling of its values) decreases the accuracy, or the roc_auc, or the mse of the machine learning model (or any other performance metric!)**. If the variables are important, a random permutation of their values will decrease dramatically any of these metrics. Contrarily, the permutation or shuffling of values should have little to no effect on the model performance metric we are assessing.\n",
    "\n",
    "The procedure: Build a machine learning model and store its performance metric! Shuffle 1 feature, and make a new prediction using the previous model! Determine the performance of this prediction! Determine the change in the performance of the prediction with the shuffled feature vs the original one! Repeat for each feature!\n",
    "\n",
    "To select features, we choose those that induced a decrease in model performance, beyond an arbitrarily set threshold. We see how to select features based on random shuffling using on a regression and classification problem. \n",
    "\n",
    "**Note** For the demonstration, I will continue to use **Random Forests**, but this selection procedure can be used with machine learning algorithm. In fact, the importance of the features are determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset_2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "Select the features by **examining only the training set** to **avoid overfit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset the indeces of the returned datasets!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML algo with all features\n",
    "\n",
    "To determine feature importance by **feature shuffling:** Build the machine learning model, for example, Random Forests! Few and shallow trees to avoid overfitting! Thenprint **roc-auc** in train and testing sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.690997114685582\n",
      "test auc score:  0.6857035229040285\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=2, random_state=2909, n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n",
    "print('train auc score: ',\n",
    "      roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1]))\n",
    "print('test auc score: ',\n",
    "      roc_auc_score(y_test, (rf.predict_proba(X_test.fillna(0)))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle features and asses performance drop\n",
    "\n",
    "**Shuffle one by one**, each feature of the dataset! Then use the dataset with the shuffled variable to make predictions with the **random forests** trained in the previous cell! Overall train roc-auc: using all the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc = roc_auc_score(y_train, (rf.predict_proba(X_train))[:, 1])\n",
    "performance_shift = []  # list to capture the performance shift\n",
    "for feature in X_train.columns:  # selection  logic\n",
    "    X_train_c = X_train.copy()\n",
    "    X_train_c[feature] = X_train_c[feature].sample(  # shuffle individual feature\n",
    "        frac=1, random_state=10).reset_index(drop=True)\n",
    "    shuff_roc = roc_auc_score(y_train, rf.predict_proba(X_train_c)[:, 1]) # make prediction!\n",
    "    drift = train_roc - shuff_roc\n",
    "    performance_shift.append(drift) # save the drop in roc-auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The list of performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -9.919140466640997e-05,\n",
       " -5.777064524881137e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -3.334693591705573e-05,\n",
       " 8.796265542265758e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.2864223244933868e-05,\n",
       " -6.957465160806198e-05,\n",
       " 4.371055238927557e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.015497219959881292,\n",
       " -0.00012937667354617766,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0013551709383483601,\n",
       " 0.0,\n",
       " -7.38081844428029e-05,\n",
       " 0.0,\n",
       " 1.2296120844856873e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0015281413151823076,\n",
       " 2.6043867067171433e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001336418904640313,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00015224539098712686,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.020099856532177e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.17743806627535e-05,\n",
       " 0.0,\n",
       " 0.0017028464517550024,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07156079421237771,\n",
       " 0.0,\n",
       " -0.00015256447891842662,\n",
       " 4.3209449511305564e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00018709114134207727,\n",
       " -8.323251390618402e-05,\n",
       " 0.00010579113180830824,\n",
       " 1.5033086339877322e-05,\n",
       " 0.0,\n",
       " 3.216945650863501e-05,\n",
       " 0.008743101448133728,\n",
       " 0.0035736702283486466,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00010268788932177308,\n",
       " 8.200559833926313e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.2970250277133388e-05,\n",
       " 0.0,\n",
       " 0.0002834152488229158,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0003512281755146951,\n",
       " 0.0,\n",
       " -0.00023584867608106297,\n",
       " 0.0,\n",
       " 0.0006831133305189585,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0010592460943602555,\n",
       " 4.597338018363928e-05,\n",
       " -4.512173000126296e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003018279707167615,\n",
       " -5.0818123703777474e-05,\n",
       " 0.0003170565545920212,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00023036126250230993,\n",
       " 0.0,\n",
       " 2.3549588167304236e-06,\n",
       " 3.656702750509666e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0066017899781302125,\n",
       " 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the list into a pandas Series for easy manipulation! Then add variable names in the index!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1    0.000000\n",
       "var_2   -0.000099\n",
       "var_3   -0.000058\n",
       "var_4    0.000000\n",
       "var_5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.Series(performance_shift)\n",
    "feature_importance.index = X_train.columns\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort the dataframe according to the drop in performance caused by feature shuffling!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_55     0.071561\n",
       "var_16     0.015497\n",
       "var_69     0.008743\n",
       "var_108    0.006602\n",
       "var_70     0.003574\n",
       "             ...   \n",
       "var_63    -0.000187\n",
       "var_102   -0.000230\n",
       "var_86    -0.000236\n",
       "var_84    -0.000351\n",
       "var_30    -0.001528\n",
       "Length: 108, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise the top 10 features that caused the major drop in the roc-auc (aka model performance)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_55     0.071561\n",
       "var_16     0.015497\n",
       "var_69     0.008743\n",
       "var_108    0.006602\n",
       "var_70     0.003574\n",
       "var_48     0.001703\n",
       "var_21     0.001355\n",
       "var_34     0.001336\n",
       "var_91     0.001059\n",
       "var_88     0.000683\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original number of features (rows in this case)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of features that cause a drop in performance when shuffled!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance>0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 30 out of the 108 features caused a drop in the performance of the random forests when their values were permuted. This means that we could select those features and discard the rest, and should keep the original random forest performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the important features!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_7', 'var_11', 'var_13', 'var_16', 'var_21', 'var_25', 'var_31',\n",
       "       'var_34', 'var_38', 'var_43', 'var_46', 'var_48', 'var_55', 'var_58',\n",
       "       'var_65', 'var_66', 'var_68', 'var_69', 'var_70', 'var_73', 'var_74',\n",
       "       'var_79', 'var_88', 'var_91', 'var_92', 'var_96', 'var_98', 'var_104',\n",
       "       'var_105', 'var_108'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance>0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features\n",
    "\n",
    "Build a **random forests** only with the selected features! Capture the selected features! Train a new random forests using only the selected features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.6954703746877449\n",
      "test auc score:  0.6932896839648326\n"
     ]
    }
   ],
   "source": [
    "selected_features = feature_importance[feature_importance > 0].index\n",
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=2,\n",
    "                            random_state=2909,\n",
    "                            n_jobs=4)\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "print(\n",
    "    'train auc score: ',# print roc-auc in train and testing sets\n",
    "    roc_auc_score(y_train, (rf.predict_proba(X_train[selected_features]))[:,1]))\n",
    "print(\n",
    "    'test auc score: ',\n",
    "    roc_auc_score(y_test, (rf.predict_proba(X_test[selected_features]))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The random forests with the selected features** show a **similar performance** (or even slightly higher) to the random forests built using all of the features. And it provides a **simpler, faster and more reliable model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('HousingPrices_train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, feature selection should be done **after data pre-processing,** so ideally, all the **categorical variables are encoded into numbers,** and then you can assess **how deterministic** they are of the target! Here for simplicity use **only numerical variables**! Select numerical columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 36), (438, 36))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['Id', 'SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset the indeces of the returned datasets!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML algo with all features\n",
    "\n",
    "Determine feature importance by **feature shuffling** so: **Build the machine learning model wanted**! Select features, for example **Random Forests**! Few and shallow trees to avoid overfitting! Then print performance metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse:  34125.46855017603\n",
      "train r2:  0.8090829266232026\n",
      "\n",
      "test rmse:  39164.18326517837\n",
      "test r2:  0.7740705281238518\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           max_depth=3,\n",
    "                           random_state=2909,\n",
    "                           n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n",
    "print('train rmse: ', mean_squared_error(y_train, rf.predict(X_train), squared=False))\n",
    "print('train r2: ', r2_score(y_train, (rf.predict(X_train))))\n",
    "print()\n",
    "print('test rmse: ', mean_squared_error(y_test, rf.predict(X_test), squared=False))\n",
    "print('test r2: ', r2_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle features and asses performance drift\n",
    "\n",
    "**Shuffle one by one**, each feature of the dataset! Use the dataset with the **shuffled variable** to make predictions! Use the **trained random forests**! Overall train rmse: use all the features! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = mean_squared_error(y_train, rf.predict(X_train), squared=False)\n",
    "performance_shift = []#  List to capture the performance shift\n",
    "for feature in X_train.columns:   # for each feature:\n",
    "    X_train_c = X_train.copy()\n",
    "    X_train_c[feature] = X_train_c[feature].sample(frac=1, random_state=11).reset_index(\n",
    "        drop=True) # shuffle individual feature\n",
    "    shuff_rmse = mean_squared_error(y_train, rf.predict(X_train_c), squared=False)  # make prediction with roc-auc!\n",
    "    drift = train_rmse - shuff_rmse \n",
    "    performance_shift.append(drift)  # store the drop in roc-auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the list into a pandas Series for easy manipulation! Add variable names in the index!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         0.000000\n",
       "LotFrontage      -45.751607\n",
       "LotArea         -390.252300\n",
       "OverallQual   -42772.508176\n",
       "OverallCond       -6.967475\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.Series(performance_shift)\n",
    "feature_importance.index = X_train.columns\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the rmse, the smaller the better! Do original_rmse - shuffled_data_rmse! If the feature was important, **the shuffled data would increase the rsme**! Thus, we are looking for negative values! Here number of features that cause a drop in performance when shuffled!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance<0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The variable names!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "       '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\n",
       "       'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', 'ScreenPorch', 'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance<0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features\n",
    "\n",
    "Compare the performance of a **random forest built only using the selected features**! Slice the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feature_importance[feature_importance<0].index\n",
    "X_train = X_train[feat]\n",
    "X_test = X_test[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 28), (1022, 28))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build and evaluate the model! Print performance metrics!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse:  34114.694591609696\n",
      "train r2:  0.8092034587666255\n",
      "\n",
      "test rmse:  39561.867880230304\n",
      "test r2:  0.7694589242329681\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           max_depth=3,\n",
    "                           random_state=2909,\n",
    "                           n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n",
    "print('train rmse: ', mean_squared_error(y_train, rf.predict(X_train), squared=False))\n",
    "print('train r2: ', r2_score(y_train, (rf.predict(X_train))))\n",
    "print()\n",
    "print('test rmse: ', mean_squared_error(y_test, rf.predict(X_test), squared=False))\n",
    "print('test r2: ', r2_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model with less features shows similar performance to that with all features.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
